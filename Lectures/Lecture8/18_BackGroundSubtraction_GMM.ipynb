{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Segmentation\n",
    "The background segmentation tools in openCV use gaussian mixture models.\n",
    "\n",
    "see https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_video/py_bg_subtraction/py_bg_subtraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackgroundSubtractorGMG\n",
    "This algorithm combines statistical background image estimation and per-pixel Bayesian segmentation. It was introduced by Andrew B. Godbehere, Akihiro Matsukawa, Ken Goldberg in their paper “Visual Tracking of Human Visitors under Variable-Lighting Conditions for a Responsive Audio Art Installation” in 2012. As per the paper, the system ran a successful interactive audio art installation called “Are We There Yet?” from March 31 - July 31 2011 at the Contemporary Jewish Museum in San Francisco, California."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackgroundSubtractorMOG\n",
    "It is a Gaussian Mixture-based Background/Foreground Segmentation Algorithm. It was introduced in the paper “An improved adaptive background mixture model for real-time tracking with shadow detection” by P. KadewTraKuPong and R. Bowden in 2001. It uses a method to model each background pixel by a mixture of K Gaussian distributions (K = 3 to 5). The weights of the mixture represent the time proportions that those colours stay in the scene. The probable background colours are the ones which stay longer and more static."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackgroundSubtractorMOG2\n",
    "It is also a Gaussian Mixture-based Background/Foreground Segmentation Algorithm. It is based on two papers by Z.Zivkovic, “Improved adaptive Gausian mixture model for background subtraction” in 2004 and “Efficient Adaptive Density Estimation per Image Pixel for the Task of Background Subtraction” in 2006. One important feature of this algorithm is that it selects the appropriate number of gaussian distribution for each pixel. (Remember, in last case, we took a K gaussian distributions throughout the algorithm). It provides better adaptibility to varying scenes due illumination changes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2.748] global /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_f6tvh9615u/croot/opencv-suite_1691620375715/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "2024-09-25 17:09:48.531 python[23708:881365] IMKClient Stall detected, *please Report* your user scenario attaching a spindump (or sysdiagnose) that captures the problem - (imkxpc_bundleIdentifierWithReply:) block performed very slowly (1.66 secs).\n"
     ]
    }
   ],
   "source": [
    "# initializing subtractor  \n",
    "# This is a persistent variable. Everytime we add data to it, the estimate is updated.  This makes it good for video too\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "\n",
    "alive = True\n",
    "\n",
    "win_name = \"Camera Filters\"\n",
    "cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n",
    "result = None\n",
    "source = cv2.VideoCapture(0)\n",
    "\n",
    "while alive:\n",
    "    has_frame, frame = source.read()\n",
    "    if not has_frame:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # applying on each frame \n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # This is from the demo on erosion and dilation\n",
    "    fgmask=(cv2.morphologyEx(fgmask,cv2.MORPH_CLOSE,kernel,iterations=10)>100)\n",
    "\n",
    "    # use the mask to remove the background\n",
    "    frame[:,:,0]=frame[:,:,0]*fgmask\n",
    "    frame[:,:,1]=frame[:,:,1]*fgmask\n",
    "    frame[:,:,2]=frame[:,:,2]*fgmask\n",
    "\n",
    "    cv2.imshow(win_name, frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"Q\") or key == ord(\"q\") or key == 27:\n",
    "        alive = False\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
