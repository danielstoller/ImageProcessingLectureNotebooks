{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "faculty = cv2.imread('/Users/theodorehuppert/Desktop/ECE1390/learnopencv/Create-AR-filters-using-Mediapipe/filters/DrGeorge.png',cv2.IMREAD_UNCHANGED)\n",
    "img = cv2.cvtColor(faculty,cv2.COLOR_BGRA2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect facial landmarks in image\n",
    "def getLandmarks(img):\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    selected_keypoint_indices = [127, 93, 58, 136, 150, 149, 176, 148, 152, 377, 400, 378, 379, 365, 288, 323, 356, 70, 63, 105, 66, 55,\n",
    "                 285, 296, 334, 293, 300, 168, 6, 195, 4, 64, 60, 94, 290, 439, 33, 160, 158, 173, 153, 144, 398, 385,\n",
    "                 387, 466, 373, 380, 61, 40, 39, 0, 269, 270, 291, 321, 405, 17, 181, 91, 78, 81, 13, 311, 306, 402, 14,\n",
    "                 178, 162, 54, 67, 10, 297, 284, 389]\n",
    "\n",
    "    height, width = img.shape[:-1]\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(max_num_faces=1, static_image_mode=True, min_detection_confidence=0.5) as face_mesh:\n",
    "\n",
    "        results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if not results.multi_face_landmarks:\n",
    "            print('Face not detected!!!')\n",
    "            return 0\n",
    "\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            values = np.array(face_landmarks.landmark)\n",
    "            face_keypnts = np.zeros((len(values), 2))\n",
    "\n",
    "            for idx,value in enumerate(values):\n",
    "                face_keypnts[idx][0] = value.x\n",
    "                face_keypnts[idx][1] = value.y\n",
    "\n",
    "            # Convert normalized points to image coordinates\n",
    "            face_keypnts = face_keypnts * (width, height)\n",
    "            face_keypnts = face_keypnts.astype('int')\n",
    "\n",
    "            relevant_keypnts = []\n",
    "\n",
    "            for i in selected_keypoint_indices:\n",
    "                relevant_keypnts.append(face_keypnts[i])\n",
    "            return relevant_keypnts\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731354569.638788  620561 gl_context.cc:357] GL version: 2.1 (2.1 INTEL-20.7.3), renderer: Intel(R) Iris(TM) Plus Graphics 640\n",
      "W0000 00:00:1731354569.652834  646193 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1731354569.672022  646193 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "pts=getLandmarks(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,51,367\n",
      "1,54,433\n",
      "2,63,507\n",
      "3,86,562\n",
      "4,106,582\n",
      "5,122,597\n",
      "6,140,609\n",
      "7,162,618\n",
      "8,193,622\n",
      "9,227,620\n",
      "10,255,612\n",
      "11,282,601\n",
      "12,308,587\n",
      "13,339,566\n",
      "14,385,510\n",
      "15,400,433\n",
      "16,399,364\n",
      "17,62,334\n",
      "18,74,324\n",
      "19,93,318\n",
      "20,120,320\n",
      "21,158,341\n",
      "22,216,340\n",
      "23,256,317\n",
      "24,290,314\n",
      "25,319,319\n",
      "26,341,330\n",
      "27,185,357\n",
      "28,183,373\n",
      "29,178,407\n",
      "30,174,445\n",
      "31,135,455\n",
      "32,157,464\n",
      "33,179,469\n",
      "34,210,464\n",
      "35,230,456\n",
      "36,88,362\n",
      "37,103,355\n",
      "38,128,353\n",
      "39,149,361\n",
      "40,133,368\n",
      "41,107,368\n",
      "42,241,361\n",
      "43,264,352\n",
      "44,292,353\n",
      "45,306,359\n",
      "46,285,367\n",
      "47,259,367\n",
      "48,122,511\n",
      "49,135,507\n",
      "50,146,505\n",
      "51,185,506\n",
      "52,232,504\n",
      "53,249,506\n",
      "54,270,509\n",
      "55,247,523\n",
      "56,229,531\n",
      "57,188,537\n",
      "58,153,531\n",
      "59,139,524\n",
      "60,131,511\n",
      "61,159,514\n",
      "62,188,516\n",
      "63,224,513\n",
      "64,267,509\n",
      "65,224,516\n",
      "66,188,518\n",
      "67,158,516\n",
      "68,50,334\n",
      "69,63,284\n",
      "70,109,252\n",
      "71,188,243\n",
      "72,280,247\n",
      "73,354,278\n",
      "74,391,329\n"
     ]
    }
   ],
   "source": [
    "idx=0\n",
    "for x,y in pts:\n",
    "    print(f\"{idx},{x},{y}\")\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MediaPipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
