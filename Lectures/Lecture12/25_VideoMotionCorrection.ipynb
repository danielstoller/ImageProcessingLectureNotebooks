{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://learnopencv.com/video-stabilization-using-point-feature-matching-in-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter(object):\n",
    "    def __init__(self, F = None, H = None, Q = None, R = None, P = None, x0 = None):\n",
    "\n",
    "        if(F is None or H is None):\n",
    "            raise ValueError(\"Set proper system dynamics.\")\n",
    "\n",
    "        self.n = F.shape[1]\n",
    "        self.m = H.shape[1]\n",
    "\n",
    "        self.F = F\n",
    "        self.H = H\n",
    "\n",
    "        self.Q = np.eye(self.n) if Q is None else Q\n",
    "        self.R = np.eye(self.n) if R is None else R\n",
    "        self.P = np.eye(self.n) if P is None else P\n",
    "        self.x = np.zeros((self.n, 1)) if x0 is None else x0\n",
    "\n",
    "    def predict(self):\n",
    "        self.x = np.matmul(self.F, self.x)\n",
    "        self.P = np.matmul(np.matmul(self.F, self.P), self.F.transpose()) + self.Q\n",
    "        return self.x\n",
    "\n",
    "    def update(self, z):\n",
    "        y = z - np.matmul(self.H, self.x)\n",
    "        S = self.R + np.matmul(self.H, np.matmul(self.P, self.H.transpose()))\n",
    "\n",
    "        K = np.matmul(np.matmul(self.P, self.H.transpose()), np.linalg.inv(S))\n",
    "        self.x = self.x + np.matmul(K, y)\n",
    "        I = np.eye(self.n)\n",
    "        self.P = np.matmul(np.matmul(I - np.matmul(K, self.H), self.P), \n",
    "        \t(I - np.matmul(K, self.H)).transpose()) + np.matmul(np.matmul(K, self.R), K.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3.414] global /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_f6tvh9615u/croot/opencv-suite_1691620375715/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "alive = True\n",
    "\n",
    "win_name = \"Motion Correction\"\n",
    "cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n",
    "result = None\n",
    "source = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "has_frame, prev_frame = source.read()\n",
    "prev_frame = cv2.flip(prev_frame, 1)\n",
    "prev_frame = cv2.cvtColor(prev_frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "prev_pts = cv2.goodFeaturesToTrack(prev_frame,maxCorners=200,qualityLevel=0.01,minDistance=30,blockSize=5)\n",
    "cv2.imshow(win_name, cv2.hconcat([prev_frame,prev_frame]))\n",
    "\n",
    "kfilt = KalmanFilter(F=np.eye(3),H=np.eye(3))\n",
    "x = np.zeros((3,1))\n",
    "\n",
    "while alive:\n",
    "    has_frame, cur_frame = source.read()\n",
    "    if not has_frame:\n",
    "        break\n",
    "\n",
    "    cur_frame = cv2.flip(cur_frame, 1)\n",
    "    cur_frame = cv2.cvtColor(cur_frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    curr_pts = cv2.goodFeaturesToTrack(prev_frame,maxCorners=200,qualityLevel=0.01,minDistance=30,blockSize=5)\n",
    "    curr_pts,status,err = cv2.calcOpticalFlowPyrLK(prev_frame,cur_frame,prev_pts,curr_pts) \n",
    "\n",
    "    # Use only matching paits\n",
    "    idx = np.where(status==1)[0]\n",
    "    \n",
    "    # Estimate a rigid body transform\n",
    "    m,_ = cv2.estimateAffinePartial2D(prev_pts[idx],curr_pts[idx])\n",
    "\n",
    "    x[0,0] = m[0,2] # dX\n",
    "    x[1,0] = m[1,2] # dY\n",
    "    x[2,0] = np.arctan2(m[1,0],m[0,0])  # rotation angle\n",
    "  \n",
    "    prev_frame=cur_frame\n",
    "    prev_pts = curr_pts\n",
    "\n",
    "    # Use the kalman filter to smooth the estimate of the states (dx,dy,rotation angle )\n",
    "    kfilt.update(x)\n",
    "    x=kfilt.predict()\n",
    "    \n",
    "    # Convert the states back to a rotation matrix\n",
    "    m[0,2]=x[0,0]\n",
    "    m[1,2]=x[1,0]\n",
    "    m[0,0]=np.cos(x[2,0])\n",
    "    m[0,1]=-np.sin(x[2,0])\n",
    "    m[1,0]=np.sin(x[2,0])\n",
    "    m[1,1]=np.cos(x[2,0])\n",
    "    \n",
    "    # Add the key points to the image for display purpose\n",
    "    for id in idx:\n",
    "        i=np.uint16(curr_pts[id][0][0])\n",
    "        j=np.uint16(curr_pts[id][0][1])\n",
    "        cur_frame=cv2.circle(cur_frame,(i,j),3,255,3)\n",
    "\n",
    "    # Apply the correction\n",
    "    cur_frame_corrected = cv2.warpAffine(cur_frame,m,(cur_frame.shape[1],cur_frame.shape[0]))\n",
    "\n",
    "    # show the uncorrected and corrected side-by-side\n",
    "    cv2.imshow(win_name, cv2.hconcat([cur_frame,cur_frame_corrected]))\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"Q\") or key == ord(\"q\") or key == 27:\n",
    "        alive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
